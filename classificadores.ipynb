{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto - Mineração de Texto e Web\n",
    "## Residência Engenharia e Ciência de dados - Samsung/UFPE\n",
    "\n",
    "### Lucas Couri - lncc2\n",
    "### Mariama Oliveira - mcso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from keras.datasets import mnist\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Conv2D, Input\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"reviews_v2.csv\")\n",
    "df = df[df[\"reviews\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>stars</th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estou aqui para relatar uma experiência que ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-06-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Já havia comprado a versão Lite, o que já ac...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bom. Bem fluído, interessante e eficaz em cu...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Estou bem chateado, ja possuía o modelo anti...</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aparelho muito bom, está lidando muito bem c...</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-05-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  stars       dates\n",
       "0    Estou aqui para relatar uma experiência que ...      5  2021-06-05\n",
       "1    Já havia comprado a versão Lite, o que já ac...      5  2021-05-07\n",
       "2    Bom. Bem fluído, interessante e eficaz em cu...      5  2021-05-07\n",
       "3    Estou bem chateado, ja possuía o modelo anti...      3  2021-05-09\n",
       "4    Aparelho muito bom, está lidando muito bem c...      4  2021-05-06"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviews    object\n",
       "stars       int64\n",
       "dates      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento (com e sem stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global variables\n",
    "other_punctuation = '—“”'  \n",
    "stop_words = stopwords.words('portuguese')\n",
    "stop_words.append('’')\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "\n",
    "\n",
    "#Function that removes punctuation \n",
    "def remove_punctuation(text):\n",
    "    punctuation_free_doc = \"\".join([i for i in text if i not in string.punctuation+other_punctuation])\n",
    "    return punctuation_free_doc\n",
    "\n",
    "\n",
    "def remove_stopwords(list_words):\n",
    "    filtered_words = [word for word in list_words if word not in stop_words]\n",
    "    return filtered_words\n",
    "\n",
    "\n",
    "def do_stemming(list_words):\n",
    "    stem_text = [stemmer.stem(word) for word in list_words]\n",
    "    return stem_text\n",
    "\n",
    "\n",
    "def pre_process(doc, basic_processing = False, no_stopwords = False, stemming = False):\n",
    "\n",
    "    final_doc = doc\n",
    "    \n",
    "    ## print(final_doc)\n",
    "\n",
    "    if basic_processing == True:\n",
    "        \n",
    "        final_doc = remove_punctuation(doc)\n",
    "        final_doc = final_doc.lower()\n",
    "\n",
    "    final_doc = nltk.word_tokenize(final_doc)\n",
    "\n",
    "    if no_stopwords == True:\n",
    "        final_doc = remove_stopwords(final_doc)    \n",
    "\n",
    "    if stemming == True:\n",
    "        final_doc = do_stemming(final_doc)\n",
    "\n",
    "    return final_doc\n",
    "\n",
    "def pre_process_all(df, pre_processing_list):\n",
    "\n",
    "    for param, index in zip(pre_processing_list, range(len(pre_processing_list))):\n",
    "        \n",
    "        df[f\"reviews_pipeline_{index}\"] = df[\"reviews\"].apply(lambda x: pre_process(x, **param))\n",
    "\n",
    "    return df\n",
    "\n",
    "pre_processing_list = [\n",
    "    {\"basic_processing\": True, \"no_stopwords\": True, \"stemming\": False},\n",
    "    {\"basic_processing\": True, \"no_stopwords\": True, \"stemming\": True}]\n",
    "\n",
    "df_pp = pre_process_all(df, pre_processing_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>stars</th>\n",
       "      <th>dates</th>\n",
       "      <th>reviews_pipeline_0</th>\n",
       "      <th>reviews_pipeline_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estou aqui para relatar uma experiência que ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-06-05</td>\n",
       "      <td>[aqui, relatar, experiência, visando, contribu...</td>\n",
       "      <td>[aqu, relat, experi, vis, contribu, amig, prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Já havia comprado a versão Lite, o que já ac...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-05-07</td>\n",
       "      <td>[havia, comprado, versão, lite, achei, maravil...</td>\n",
       "      <td>[hav, compr, vers, lit, ach, maravilh, porém, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bom. Bem fluído, interessante e eficaz em cu...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-05-07</td>\n",
       "      <td>[bom, bem, fluído, interessante, eficaz, cumpr...</td>\n",
       "      <td>[bom, bem, flu, interess, eficaz, cumpr, prome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Estou bem chateado, ja possuía o modelo anti...</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-05-09</td>\n",
       "      <td>[bem, chateado, ja, possuía, modelo, antigo, b...</td>\n",
       "      <td>[bem, chate, ja, possuí, model, antig, bem, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aparelho muito bom, está lidando muito bem c...</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>[aparelho, bom, lidando, bem, home, tv, apenas...</td>\n",
       "      <td>[aparelh, bom, lid, bem, hom, tv, apen, porém,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  stars       dates  \\\n",
       "0    Estou aqui para relatar uma experiência que ...      5  2021-06-05   \n",
       "1    Já havia comprado a versão Lite, o que já ac...      5  2021-05-07   \n",
       "2    Bom. Bem fluído, interessante e eficaz em cu...      5  2021-05-07   \n",
       "3    Estou bem chateado, ja possuía o modelo anti...      3  2021-05-09   \n",
       "4    Aparelho muito bom, está lidando muito bem c...      4  2021-05-06   \n",
       "\n",
       "                                  reviews_pipeline_0  \\\n",
       "0  [aqui, relatar, experiência, visando, contribu...   \n",
       "1  [havia, comprado, versão, lite, achei, maravil...   \n",
       "2  [bom, bem, fluído, interessante, eficaz, cumpr...   \n",
       "3  [bem, chateado, ja, possuía, modelo, antigo, b...   \n",
       "4  [aparelho, bom, lidando, bem, home, tv, apenas...   \n",
       "\n",
       "                                  reviews_pipeline_1  \n",
       "0  [aqu, relat, experi, vis, contribu, amig, prob...  \n",
       "1  [hav, compr, vers, lit, ach, maravilh, porém, ...  \n",
       "2  [bom, bem, flu, interess, eficaz, cumpr, prome...  \n",
       "3  [bem, chate, ja, possuí, model, antig, bem, co...  \n",
       "4  [aparelh, bom, lid, bem, hom, tv, apen, porém,...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews_pipeline_0</th>\n",
       "      <th>reviews_pipeline_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[aqui, relatar, experiência, visando, contribu...</td>\n",
       "      <td>[aqu, relat, experi, vis, contribu, amig, prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[havia, comprado, versão, lite, achei, maravil...</td>\n",
       "      <td>[hav, compr, vers, lit, ach, maravilh, porém, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bom, bem, fluído, interessante, eficaz, cumpr...</td>\n",
       "      <td>[bom, bem, flu, interess, eficaz, cumpr, prome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[bem, chateado, ja, possuía, modelo, antigo, b...</td>\n",
       "      <td>[bem, chate, ja, possuí, model, antig, bem, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[aparelho, bom, lidando, bem, home, tv, apenas...</td>\n",
       "      <td>[aparelh, bom, lid, bem, hom, tv, apen, porém,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>[chegou, super, rápido, atendeu, superou, toda...</td>\n",
       "      <td>[cheg, sup, rápid, atend, super, tod, expect]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>[facil, instalação, configuração, entrega, sup...</td>\n",
       "      <td>[facil, instal, configur, entreg, sup, rápid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>[amei, produto, unico, problema, pra, mim, nao...</td>\n",
       "      <td>[ame, produt, unic, problem, pra, mim, nao, hbo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>[funciona, beleza, rede, internet, sendo, boa,...</td>\n",
       "      <td>[func, bel, red, internet, send, boa, tud, bem]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>[aparelho, bom, penanao, poder, instalar, hbo,...</td>\n",
       "      <td>[aparelh, bom, penana, pod, instal, hbo, max]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5003 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     reviews_pipeline_0  \\\n",
       "0     [aqui, relatar, experiência, visando, contribu...   \n",
       "1     [havia, comprado, versão, lite, achei, maravil...   \n",
       "2     [bom, bem, fluído, interessante, eficaz, cumpr...   \n",
       "3     [bem, chateado, ja, possuía, modelo, antigo, b...   \n",
       "4     [aparelho, bom, lidando, bem, home, tv, apenas...   \n",
       "...                                                 ...   \n",
       "5002  [chegou, super, rápido, atendeu, superou, toda...   \n",
       "5003  [facil, instalação, configuração, entrega, sup...   \n",
       "5004  [amei, produto, unico, problema, pra, mim, nao...   \n",
       "5005  [funciona, beleza, rede, internet, sendo, boa,...   \n",
       "5006  [aparelho, bom, penanao, poder, instalar, hbo,...   \n",
       "\n",
       "                                     reviews_pipeline_1  \n",
       "0     [aqu, relat, experi, vis, contribu, amig, prob...  \n",
       "1     [hav, compr, vers, lit, ach, maravilh, porém, ...  \n",
       "2     [bom, bem, flu, interess, eficaz, cumpr, prome...  \n",
       "3     [bem, chate, ja, possuí, model, antig, bem, co...  \n",
       "4     [aparelh, bom, lid, bem, hom, tv, apen, porém,...  \n",
       "...                                                 ...  \n",
       "5002      [cheg, sup, rápid, atend, super, tod, expect]  \n",
       "5003      [facil, instal, configur, entreg, sup, rápid]  \n",
       "5004   [ame, produt, unic, problem, pra, mim, nao, hbo]  \n",
       "5005    [func, bel, red, internet, send, boa, tud, bem]  \n",
       "5006      [aparelh, bom, penana, pod, instal, hbo, max]  \n",
       "\n",
       "[5003 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pp[[\"reviews_pipeline_0\", \"reviews_pipeline_1\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp[\"class\"] = df_pp[\"stars\"].apply(lambda x : 1 if x >=4 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão train e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pp[[\"reviews_pipeline_0\", \"reviews_pipeline_1\"]]\n",
    "y = df_pp[\"class\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews_pipeline_0</th>\n",
       "      <th>reviews_pipeline_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4688</th>\n",
       "      <td>[chegou, antes, prazo, mostrou, excelente, pro...</td>\n",
       "      <td>[cheg, ant, praz, mostr, excel, produt, val, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3802</th>\n",
       "      <td>[melhor, produto, comprei, pra, tv, igual, fun...</td>\n",
       "      <td>[melhor, produt, compr, pra, tv, igual, func, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4442</th>\n",
       "      <td>[gostei, falta, globoplay, pra, mim, único, de...</td>\n",
       "      <td>[gost, falt, globoplay, pra, mim, únic, defeit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>[fire, sitck, prático, funciona, bem, transfor...</td>\n",
       "      <td>[fir, sitck, prát, func, bem, transform, tv, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4612</th>\n",
       "      <td>[to, demais, super, fácil, praticovelocidade, ...</td>\n",
       "      <td>[to, demal, sup, fácil, praticoveloc, respost,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     reviews_pipeline_0  \\\n",
       "4688  [chegou, antes, prazo, mostrou, excelente, pro...   \n",
       "3802  [melhor, produto, comprei, pra, tv, igual, fun...   \n",
       "4442  [gostei, falta, globoplay, pra, mim, único, de...   \n",
       "1146  [fire, sitck, prático, funciona, bem, transfor...   \n",
       "4612  [to, demais, super, fácil, praticovelocidade, ...   \n",
       "\n",
       "                                     reviews_pipeline_1  \n",
       "4688  [cheg, ant, praz, mostr, excel, produt, val, c...  \n",
       "3802  [melhor, produt, compr, pra, tv, igual, func, ...  \n",
       "4442  [gost, falt, globoplay, pra, mim, únic, defeit...  \n",
       "1146  [fir, sitck, prát, func, bem, transform, tv, c...  \n",
       "4612  [to, demal, sup, fácil, praticoveloc, respost,...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformando tokens em string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_join = []\n",
    "X_train_join.append(X_train[\"reviews_pipeline_0\"].apply(\" \".join))\n",
    "X_train_join.append(X_train[\"reviews_pipeline_1\"].apply(\" \".join))\n",
    "X_train_join[0] = X_train_join[0].to_numpy()\n",
    "X_train_join[1] = X_train_join[1].to_numpy()\n",
    "\n",
    "X_test_join = []\n",
    "X_test_join.append(X_test[\"reviews_pipeline_0\"].apply(\" \".join))\n",
    "X_test_join.append(X_test[\"reviews_pipeline_1\"].apply(\" \".join))\n",
    "X_test_join[0] = X_test_join[0].to_numpy()\n",
    "X_test_join[1] = X_test_join[1].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificadores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest com BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3502, 2000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",   \n",
    "                             tokenizer = None,    \n",
    "                             preprocessor = None, \n",
    "                             stop_words = None,   \n",
    "                             max_features = 2000) \n",
    "\n",
    "#List with BoWs (pipeline 0 and 1)\n",
    "X_train_vec = []\n",
    "X_train_vec.append(vectorizer.fit_transform(X_train_join[0]))\n",
    "X_train_vec.append(vectorizer.fit_transform(X_train_join[1]))\n",
    "\n",
    "X_test_vec = []\n",
    "X_test_vec.append(vectorizer.fit_transform(X_test_join[0]))\n",
    "X_test_vec.append(vectorizer.fit_transform(X_test_join[1]))\n",
    "\n",
    "\n",
    "print(X_train_vec[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier() \n",
    "forest = forest.fit(X_train_vec[0], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.11      0.14       170\n",
      "           1       0.89      0.94      0.92      1331\n",
      "\n",
      "    accuracy                           0.85      1501\n",
      "   macro avg       0.55      0.53      0.53      1501\n",
      "weighted avg       0.81      0.85      0.83      1501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = forest.predict(X_test_vec[0]) \n",
    "result = forest.predict(X_test_vec[0])\n",
    "print(classification_report(y_test, result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  19,  151],\n",
       "       [  76, 1255]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Com Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier() \n",
    "forest = forest.fit(X_train_vec[1], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.14      0.17       170\n",
      "           1       0.90      0.95      0.92      1331\n",
      "\n",
      "    accuracy                           0.85      1501\n",
      "   macro avg       0.57      0.54      0.55      1501\n",
      "weighted avg       0.82      0.85      0.84      1501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = forest.predict(X_test_vec[1]) \n",
    "result = forest.predict(X_test_vec[1])\n",
    "print(classification_report(y_test, result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  23,  147],\n",
       "       [  71, 1260]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes (CNN, LSTM e BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.layers.TextVectorization(\n",
    "#     max_tokens=None,\n",
    "#     standardize='lower_and_strip_punctuation',\n",
    "#     split='whitespace',\n",
    "#     ngrams=None,\n",
    "#     output_mode='int',\n",
    "#     output_sequence_length=None,\n",
    "#     pad_to_max_tokens=False,\n",
    "#     vocabulary=None,\n",
    "#     idf_weights=None,\n",
    "#     sparse=False,\n",
    "#     ragged=False,\n",
    "#     **kwargs\n",
    "# )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['chegou antes prazo mostrou excelente produto vale compra',\n",
       "       'melhor produto comprei pra tv igual funciona bem',\n",
       "       'gostei falta globoplay pra mim único defeito momento', ...,\n",
       "       'atendeu todas expectativas ótimo produto fácil instalação controle prático funciona perfeitamente',\n",
       "       'funcionou tv sansung usar tv smart atendeu',\n",
       "       'comprei pra dar upgrade tv ameinão fácil instalar tudo intuitivo rápidoestou amando'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_join[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "encoder = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE,\n",
    "                                            standardize=None\n",
    "                                            )\n",
    "#encoder.adapt(train_dataset.map(lambda text, label: text))\n",
    "encoder.adapt(X_train_join[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 45  67 155 ...   0   0   0]\n",
      " [ 31   3  37 ...   0   0   0]\n",
      " [ 26  52  34 ...   0   0   0]\n",
      " ...\n",
      " [ 99  93  54 ...   0   0   0]\n",
      " [ 84   2   1 ...   0   0   0]\n",
      " [ 37  23 269 ...   0   0   0]], shape=(3502, 180), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "vectorized_text = encoder(X_train_join[0])\n",
    "print(vectorized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'tv', 'produto', 'controle', 'fácil', 'bem', 'bom',\n",
       "       'alexa', 'instalar', 'fire', 'stick', 'aparelho', 'smart',\n",
       "       'excelente', 'amazon', 'instalação', 'hbo', 'rápido', 'recomendo'],\n",
       "      dtype='<U17')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "110/110 [==============================] - 12s 59ms/step - loss: 0.5996 - accuracy: 0.2778 - val_loss: 0.4456 - val_accuracy: 0.8396\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.3935 - accuracy: 0.8664 - val_loss: 0.3592 - val_accuracy: 0.8792\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 4s 33ms/step - loss: 0.3246 - accuracy: 0.8855 - val_loss: 0.3114 - val_accuracy: 0.8844\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.2827 - accuracy: 0.8903 - val_loss: 0.2774 - val_accuracy: 0.8906\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.2439 - accuracy: 0.9058 - val_loss: 0.2453 - val_accuracy: 0.8958\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.2125 - accuracy: 0.9212 - val_loss: 0.2356 - val_accuracy: 0.8958\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 4s 32ms/step - loss: 0.1910 - accuracy: 0.9260 - val_loss: 0.2372 - val_accuracy: 0.9042\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 4s 33ms/step - loss: 0.1727 - accuracy: 0.9318 - val_loss: 0.2591 - val_accuracy: 0.9052\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 4s 37ms/step - loss: 0.1601 - accuracy: 0.9375 - val_loss: 0.2387 - val_accuracy: 0.8938\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 4s 34ms/step - loss: 0.1506 - accuracy: 0.9389 - val_loss: 0.2519 - val_accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_join[0], y_train, epochs=10,\n",
    "                    batch_size = 32,\n",
    "                    validation_data= (X_test_join[0], y_test),\n",
    "                    validation_steps=30\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1525, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1514, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1507, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1471, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"sequential\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8052/1076518984.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#test_loss, test_acc = model.evaluate(test_dataset)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_join\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1525, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1514, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1507, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1471, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"sequential\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>]\n"
     ]
    }
   ],
   "source": [
    "#test_dataset = tf.data.Dataset.from_tensor_slices((X_test_join[0].to_list(), y_test.to_list()))\n",
    "\n",
    "#test_loss, test_acc = model.evaluate(test_dataset)\n",
    "test_loss, test_acc = model.evaluate((X_test_join[0], y_test))\n",
    "\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.ylim(None, 1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_graphs(history, 'loss')\n",
    "plt.ylim(0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = ('The movie was cool. The animation and the graphics '\n",
    "               'were out of this world. I would recommend this movie.')\n",
    "predictions = model.predict(np.array([sample_text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8003219c8c57211ee3be347d121ba14ebad7276cdae3d94be72d9e4e17f9edd5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
