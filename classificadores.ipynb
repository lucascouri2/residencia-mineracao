{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto - Mineração de Texto e Web\n",
    "## Residência Engenharia e Ciência de dados - Samsung/UFPE\n",
    "\n",
    "### Lucas Couri - lncc2\n",
    "### Mariama Oliveira - mcso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.cluster.vq import vq\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from keras.datasets import mnist\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Conv2D, Input\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dataset_split \n",
    "import networks\n",
    "import bert\n",
    "import rm_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"reviews_v2.csv\")\n",
    "df = df[df[\"reviews\"].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento (com e sem stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global variables\n",
    "other_punctuation = '—“”'  \n",
    "stop_words = stopwords.words('portuguese')\n",
    "stop_words.append('’')\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "\n",
    "\n",
    "#Function that removes punctuation \n",
    "def remove_punctuation(text):\n",
    "    punctuation_free_doc = \"\".join([i for i in text if i not in string.punctuation+other_punctuation])\n",
    "    return punctuation_free_doc\n",
    "\n",
    "\n",
    "def remove_stopwords(list_words):\n",
    "    filtered_words = [word for word in list_words if word not in stop_words]\n",
    "    return filtered_words\n",
    "\n",
    "\n",
    "def do_stemming(list_words):\n",
    "    stem_text = [stemmer.stem(word) for word in list_words]\n",
    "    return stem_text\n",
    "\n",
    "\n",
    "def pre_process(doc, basic_processing = False, no_stopwords = False, stemming = False):\n",
    "\n",
    "    final_doc = doc\n",
    "    \n",
    "    ## print(final_doc)\n",
    "\n",
    "    if basic_processing == True:\n",
    "        \n",
    "        final_doc = remove_punctuation(doc)\n",
    "        final_doc = final_doc.lower()\n",
    "\n",
    "    final_doc = nltk.word_tokenize(final_doc)\n",
    "\n",
    "    if no_stopwords == True:\n",
    "        final_doc = remove_stopwords(final_doc)    \n",
    "\n",
    "    if stemming == True:\n",
    "        final_doc = do_stemming(final_doc)\n",
    "\n",
    "    return final_doc\n",
    "\n",
    "def pre_process_all(df, pre_processing_list):\n",
    "\n",
    "    for param, index in zip(pre_processing_list, range(len(pre_processing_list))):\n",
    "        \n",
    "        df[f\"reviews_pipeline_{index}\"] = df[\"reviews\"].apply(lambda x: pre_process(x, **param))\n",
    "\n",
    "    return df\n",
    "\n",
    "pre_processing_list = [\n",
    "    {\"basic_processing\": True, \"no_stopwords\": True, \"stemming\": False},\n",
    "    {\"basic_processing\": True, \"no_stopwords\": True, \"stemming\": True}]\n",
    "\n",
    "df_pp = pre_process_all(df, pre_processing_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp[\"class\"] = df_pp[\"stars\"].apply(lambda x : 1 if x >=4 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão Train, Validation e Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unbalanced dataset\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = dataset_split.split_data(df_pp)\n",
    "\n",
    "#Balanced dataset\n",
    "X_train_b, X_valid_b, X_test_b, y_train_b, y_valid_b, y_test_b = dataset_split.split_data(df_pp, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformando tokens em string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_string(df):\n",
    "    X_train_join = []\n",
    "    X_train_join.append(df[\"reviews_pipeline_0\"].apply(\" \".join))\n",
    "    X_train_join.append(df[\"reviews_pipeline_1\"].apply(\" \".join))\n",
    "    X_train_join[0] = X_train_join[0].to_numpy()\n",
    "    X_train_join[1] = X_train_join[1].to_numpy()\n",
    "\n",
    "    return X_train_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unbalanced data\n",
    "X_train_join = tokens_to_string(X_train)\n",
    "X_test_join = tokens_to_string(X_test)\n",
    "X_valid_join = tokens_to_string(X_valid)\n",
    "\n",
    "#Balanced data\n",
    "X_train_join_b = tokens_to_string(X_train_b)\n",
    "X_test_join_b = tokens_to_string(X_test_b)\n",
    "X_valid_join_b = tokens_to_string(X_valid_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificadores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest com BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bag_of_words(X_train_join, X_valid_join, X_test_join):\n",
    "    vectorizer = CountVectorizer(analyzer = \"word\",   \n",
    "                                tokenizer = None,    \n",
    "                                preprocessor = None, \n",
    "                                stop_words = None,   \n",
    "                                max_features = 2000) \n",
    "\n",
    "    #List with BoWs (pipeline 0 and 1)\n",
    "    X_train_vec = []\n",
    "    X_train_vec.append(vectorizer.fit_transform(X_train_join[0]))\n",
    "    X_train_vec.append(vectorizer.fit_transform(X_train_join[1]))\n",
    "\n",
    "    X_test_vec = []\n",
    "    X_test_vec.append(vectorizer.fit_transform(X_test_join[0]))\n",
    "    X_test_vec.append(vectorizer.fit_transform(X_test_join[1]))\n",
    "\n",
    "    X_valid_vec = []\n",
    "    X_valid_vec.append(vectorizer.fit_transform(X_valid_join[0]))\n",
    "    X_valid_vec.append(vectorizer.fit_transform(X_valid_join[1]))\n",
    "\n",
    "\n",
    "    return X_train_vec, X_valid_vec, X_test_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unbalanced data\n",
    "X_train_vec, X_valid_vec, X_test_vec = get_bag_of_words(X_train_join, X_valid_join, X_test_join)\n",
    "\n",
    "#Balanced data\n",
    "X_train_vec_b, X_valid_vec_b, X_test_vec_b = get_bag_of_words(X_train_join_b, X_valid_join_b, X_test_join_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_rf(X_train_vec, y_train, X_valid_vec, y_valid, X_test_vec, y_test):\n",
    "    #Get best parameters\n",
    "    best_params = rm_forest.get_best_parameters(X_train_vec, X_valid_vec, y_train, y_valid)\n",
    "    \n",
    "    #Train model with best parameters\n",
    "    forest = RandomForestClassifier(**best_params) \n",
    "    forest = forest.fit(X_train_vec, y_train)\n",
    "\n",
    "    #Predict test dataset\n",
    "    predictions = forest.predict(X_test_vec) \n",
    "    result = forest.predict(X_test_vec)\n",
    "    print(classification_report(y_test, result))\n",
    "    print(confusion_matrix(y_test, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-31 15:58:40,000]\u001b[0m A new study created in memory with name: no-name-70094e89-a24f-4ef8-b5c8-d35bc31321be\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:58:41,246]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'n_estimators': 721, 'max_depth': 9, 'criterion': 'gini'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:58:43,208]\u001b[0m Trial 1 finished with value: 0.0 and parameters: {'n_estimators': 544, 'max_depth': 34, 'criterion': 'entropy'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:58:44,579]\u001b[0m Trial 2 finished with value: 0.0 and parameters: {'n_estimators': 959, 'max_depth': 5, 'criterion': 'gini'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:58:45,153]\u001b[0m Trial 3 finished with value: 0.032 and parameters: {'n_estimators': 199, 'max_depth': 29, 'criterion': 'gini'}. Best is trial 3 with value: 0.032.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:58:46,487]\u001b[0m Trial 4 finished with value: 0.0 and parameters: {'n_estimators': 890, 'max_depth': 3, 'criterion': 'entropy'}. Best is trial 3 with value: 0.032.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:58:47,093]\u001b[0m Trial 5 finished with value: 0.0 and parameters: {'n_estimators': 249, 'max_depth': 19, 'criterion': 'entropy'}. Best is trial 3 with value: 0.032.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:58:51,309]\u001b[0m Trial 6 finished with value: 0.10778443113772455 and parameters: {'n_estimators': 921, 'max_depth': 67, 'criterion': 'gini'}. Best is trial 6 with value: 0.10778443113772455.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:58:56,574]\u001b[0m Trial 7 finished with value: 0.08333333333333333 and parameters: {'n_estimators': 970, 'max_depth': 80, 'criterion': 'entropy'}. Best is trial 6 with value: 0.10778443113772455.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:58:57,065]\u001b[0m Trial 8 finished with value: 0.0 and parameters: {'n_estimators': 324, 'max_depth': 6, 'criterion': 'entropy'}. Best is trial 6 with value: 0.10778443113772455.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:58:58,139]\u001b[0m Trial 9 finished with value: 0.0 and parameters: {'n_estimators': 530, 'max_depth': 15, 'criterion': 'entropy'}. Best is trial 6 with value: 0.10778443113772455.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:02,375]\u001b[0m Trial 10 finished with value: 0.12429378531073446 and parameters: {'n_estimators': 761, 'max_depth': 109, 'criterion': 'gini'}. Best is trial 10 with value: 0.12429378531073446.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:06,339]\u001b[0m Trial 11 finished with value: 0.10285714285714286 and parameters: {'n_estimators': 728, 'max_depth': 122, 'criterion': 'gini'}. Best is trial 10 with value: 0.12429378531073446.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:09,393]\u001b[0m Trial 12 finished with value: 0.09032258064516129 and parameters: {'n_estimators': 772, 'max_depth': 60, 'criterion': 'gini'}. Best is trial 10 with value: 0.12429378531073446.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:09,544]\u001b[0m Trial 13 finished with value: 0.1229050279329609 and parameters: {'n_estimators': 32, 'max_depth': 55, 'criterion': 'gini'}. Best is trial 10 with value: 0.12429378531073446.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:10,055]\u001b[0m Trial 14 finished with value: 0.13114754098360654 and parameters: {'n_estimators': 81, 'max_depth': 115, 'criterion': 'gini'}. Best is trial 14 with value: 0.13114754098360654.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:10,131]\u001b[0m Trial 15 finished with value: 0.11627906976744187 and parameters: {'n_estimators': 12, 'max_depth': 124, 'criterion': 'gini'}. Best is trial 14 with value: 0.13114754098360654.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:11,222]\u001b[0m Trial 16 finished with value: 0.016 and parameters: {'n_estimators': 389, 'max_depth': 31, 'criterion': 'gini'}. Best is trial 14 with value: 0.13114754098360654.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:12,034]\u001b[0m Trial 17 finished with value: 0.0 and parameters: {'n_estimators': 581, 'max_depth': 2, 'criterion': 'gini'}. Best is trial 14 with value: 0.13114754098360654.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:14,162]\u001b[0m Trial 18 finished with value: 0.04477611940298508 and parameters: {'n_estimators': 667, 'max_depth': 42, 'criterion': 'gini'}. Best is trial 14 with value: 0.13114754098360654.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:15,076]\u001b[0m Trial 19 finished with value: 0.1375661375661376 and parameters: {'n_estimators': 170, 'max_depth': 98, 'criterion': 'gini'}. Best is trial 19 with value: 0.1375661375661376.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.10      0.13       167\n",
      "           1       0.89      0.96      0.92      1334\n",
      "\n",
      "    accuracy                           0.86      1501\n",
      "   macro avg       0.55      0.53      0.53      1501\n",
      "weighted avg       0.82      0.86      0.84      1501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Unbalanced data\n",
    "pipeline_rf(X_train_vec[0], y_train, X_valid_vec[0], y_valid, X_test_vec[0], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-31 15:56:41,990]\u001b[0m A new study created in memory with name: no-name-9de3d36b-1fe0-4c01-9c52-7a3a69ac6990\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:56:43,439]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'n_estimators': 940, 'max_depth': 5, 'criterion': 'entropy'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:56:43,539]\u001b[0m Trial 1 finished with value: 0.0 and parameters: {'n_estimators': 64, 'max_depth': 4, 'criterion': 'gini'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:56:43,612]\u001b[0m Trial 2 finished with value: 0.0 and parameters: {'n_estimators': 49, 'max_depth': 2, 'criterion': 'gini'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:56:43,939]\u001b[0m Trial 3 finished with value: 0.0 and parameters: {'n_estimators': 239, 'max_depth': 2, 'criterion': 'gini'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:56:45,077]\u001b[0m Trial 4 finished with value: 0.0 and parameters: {'n_estimators': 742, 'max_depth': 3, 'criterion': 'entropy'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:56:50,498]\u001b[0m Trial 5 finished with value: 0.12021857923497267 and parameters: {'n_estimators': 847, 'max_depth': 97, 'criterion': 'gini'}. Best is trial 5 with value: 0.12021857923497267.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:56:51,640]\u001b[0m Trial 6 finished with value: 0.0 and parameters: {'n_estimators': 641, 'max_depth': 8, 'criterion': 'entropy'}. Best is trial 5 with value: 0.12021857923497267.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:56:53,651]\u001b[0m Trial 7 finished with value: 0.01639344262295082 and parameters: {'n_estimators': 624, 'max_depth': 27, 'criterion': 'gini'}. Best is trial 5 with value: 0.12021857923497267.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:56:57,296]\u001b[0m Trial 8 finished with value: 0.04411764705882353 and parameters: {'n_estimators': 886, 'max_depth': 39, 'criterion': 'gini'}. Best is trial 5 with value: 0.12021857923497267.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:56:58,849]\u001b[0m Trial 9 finished with value: 0.0 and parameters: {'n_estimators': 891, 'max_depth': 8, 'criterion': 'entropy'}. Best is trial 5 with value: 0.12021857923497267.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:57:01,585]\u001b[0m Trial 10 finished with value: 0.11956521739130434 and parameters: {'n_estimators': 388, 'max_depth': 100, 'criterion': 'gini'}. Best is trial 5 with value: 0.12021857923497267.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:57:04,283]\u001b[0m Trial 11 finished with value: 0.11827956989247311 and parameters: {'n_estimators': 389, 'max_depth': 124, 'criterion': 'gini'}. Best is trial 5 with value: 0.12021857923497267.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:57:07,166]\u001b[0m Trial 12 finished with value: 0.1208791208791209 and parameters: {'n_estimators': 422, 'max_depth': 94, 'criterion': 'gini'}. Best is trial 12 with value: 0.1208791208791209.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:57:09,805]\u001b[0m Trial 13 finished with value: 0.08974358974358974 and parameters: {'n_estimators': 505, 'max_depth': 57, 'criterion': 'gini'}. Best is trial 12 with value: 0.1208791208791209.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:57:10,539]\u001b[0m Trial 14 finished with value: 0.016806722689075633 and parameters: {'n_estimators': 263, 'max_depth': 20, 'criterion': 'gini'}. Best is trial 12 with value: 0.1208791208791209.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:57:15,019]\u001b[0m Trial 15 finished with value: 0.11904761904761905 and parameters: {'n_estimators': 775, 'max_depth': 66, 'criterion': 'gini'}. Best is trial 12 with value: 0.1208791208791209.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:57:18,092]\u001b[0m Trial 16 finished with value: 0.08284023668639053 and parameters: {'n_estimators': 524, 'max_depth': 68, 'criterion': 'gini'}. Best is trial 12 with value: 0.1208791208791209.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:57:19,377]\u001b[0m Trial 17 finished with value: 0.030303030303030307 and parameters: {'n_estimators': 358, 'max_depth': 33, 'criterion': 'gini'}. Best is trial 12 with value: 0.1208791208791209.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:57:20,832]\u001b[0m Trial 18 finished with value: 0.0 and parameters: {'n_estimators': 635, 'max_depth': 13, 'criterion': 'entropy'}. Best is trial 12 with value: 0.1208791208791209.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:57:27,355]\u001b[0m Trial 19 finished with value: 0.11956521739130434 and parameters: {'n_estimators': 997, 'max_depth': 87, 'criterion': 'gini'}. Best is trial 12 with value: 0.1208791208791209.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.26      0.20       167\n",
      "           1       0.90      0.82      0.86      1334\n",
      "\n",
      "    accuracy                           0.76      1501\n",
      "   macro avg       0.53      0.54      0.53      1501\n",
      "weighted avg       0.82      0.76      0.78      1501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Balanced data\n",
    "pipeline_rf(X_train_vec_b[0], y_train_b, X_valid_vec_b[0], y_valid_b, X_test_vec_b[0], y_test_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Com stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-31 15:59:16,350]\u001b[0m A new study created in memory with name: no-name-251c84ab-1d55-476f-9b1c-4e8fbcaf2858\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:20,691]\u001b[0m Trial 0 finished with value: 0.07407407407407407 and parameters: {'n_estimators': 965, 'max_depth': 53, 'criterion': 'entropy'}. Best is trial 0 with value: 0.07407407407407407.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:22,864]\u001b[0m Trial 1 finished with value: 0.032520325203252036 and parameters: {'n_estimators': 598, 'max_depth': 35, 'criterion': 'entropy'}. Best is trial 0 with value: 0.07407407407407407.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:25,115]\u001b[0m Trial 2 finished with value: 0.016666666666666666 and parameters: {'n_estimators': 797, 'max_depth': 25, 'criterion': 'entropy'}. Best is trial 0 with value: 0.07407407407407407.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:26,030]\u001b[0m Trial 3 finished with value: 0.05882352941176471 and parameters: {'n_estimators': 286, 'max_depth': 33, 'criterion': 'gini'}. Best is trial 0 with value: 0.07407407407407407.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:28,390]\u001b[0m Trial 4 finished with value: 0.07462686567164178 and parameters: {'n_estimators': 547, 'max_depth': 50, 'criterion': 'entropy'}. Best is trial 4 with value: 0.07462686567164178.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:30,317]\u001b[0m Trial 5 finished with value: 0.0979020979020979 and parameters: {'n_estimators': 371, 'max_depth': 82, 'criterion': 'entropy'}. Best is trial 5 with value: 0.0979020979020979.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:31,198]\u001b[0m Trial 6 finished with value: 0.0 and parameters: {'n_estimators': 627, 'max_depth': 2, 'criterion': 'gini'}. Best is trial 5 with value: 0.0979020979020979.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:32,730]\u001b[0m Trial 7 finished with value: 0.0 and parameters: {'n_estimators': 893, 'max_depth': 9, 'criterion': 'gini'}. Best is trial 5 with value: 0.0979020979020979.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:34,531]\u001b[0m Trial 8 finished with value: 0.048 and parameters: {'n_estimators': 699, 'max_depth': 27, 'criterion': 'gini'}. Best is trial 5 with value: 0.0979020979020979.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:35,505]\u001b[0m Trial 9 finished with value: 0.0 and parameters: {'n_estimators': 669, 'max_depth': 4, 'criterion': 'entropy'}. Best is trial 5 with value: 0.0979020979020979.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:35,906]\u001b[0m Trial 10 finished with value: 0.09271523178807947 and parameters: {'n_estimators': 72, 'max_depth': 124, 'criterion': 'entropy'}. Best is trial 5 with value: 0.0979020979020979.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:36,118]\u001b[0m Trial 11 finished with value: 0.10256410256410256 and parameters: {'n_estimators': 36, 'max_depth': 108, 'criterion': 'entropy'}. Best is trial 11 with value: 0.10256410256410256.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:37,887]\u001b[0m Trial 12 finished with value: 0.09210526315789473 and parameters: {'n_estimators': 314, 'max_depth': 81, 'criterion': 'entropy'}. Best is trial 11 with value: 0.10256410256410256.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:37,998]\u001b[0m Trial 13 finished with value: 0.09090909090909091 and parameters: {'n_estimators': 17, 'max_depth': 122, 'criterion': 'entropy'}. Best is trial 11 with value: 0.10256410256410256.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:38,661]\u001b[0m Trial 14 finished with value: 0.0 and parameters: {'n_estimators': 348, 'max_depth': 10, 'criterion': 'entropy'}. Best is trial 11 with value: 0.10256410256410256.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:39,011]\u001b[0m Trial 15 finished with value: 0.016949152542372885 and parameters: {'n_estimators': 150, 'max_depth': 16, 'criterion': 'entropy'}. Best is trial 11 with value: 0.10256410256410256.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:41,466]\u001b[0m Trial 16 finished with value: 0.0979020979020979 and parameters: {'n_estimators': 475, 'max_depth': 67, 'criterion': 'entropy'}. Best is trial 11 with value: 0.10256410256410256.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:43,872]\u001b[0m Trial 17 finished with value: 0.10526315789473684 and parameters: {'n_estimators': 455, 'max_depth': 68, 'criterion': 'entropy'}. Best is trial 17 with value: 0.10526315789473684.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:44,150]\u001b[0m Trial 18 finished with value: 0.0 and parameters: {'n_estimators': 181, 'max_depth': 6, 'criterion': 'gini'}. Best is trial 17 with value: 0.10526315789473684.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:45,085]\u001b[0m Trial 19 finished with value: 0.0 and parameters: {'n_estimators': 454, 'max_depth': 14, 'criterion': 'entropy'}. Best is trial 17 with value: 0.10526315789473684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.07      0.11       167\n",
      "           1       0.89      0.97      0.93      1334\n",
      "\n",
      "    accuracy                           0.87      1501\n",
      "   macro avg       0.55      0.52      0.52      1501\n",
      "weighted avg       0.82      0.87      0.84      1501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_rf(X_train_vec[1], y_train, X_valid_vec[1], y_valid, X_test_vec[1], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-31 15:59:48,118]\u001b[0m A new study created in memory with name: no-name-33cfd233-a2da-4307-9265-c269fb574187\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:55,098]\u001b[0m Trial 0 finished with value: 0.15228426395939085 and parameters: {'n_estimators': 995, 'max_depth': 118, 'criterion': 'gini'}. Best is trial 0 with value: 0.15228426395939085.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 15:59:56,074]\u001b[0m Trial 1 finished with value: 0.0 and parameters: {'n_estimators': 410, 'max_depth': 13, 'criterion': 'entropy'}. Best is trial 0 with value: 0.15228426395939085.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 16:00:00,484]\u001b[0m Trial 2 finished with value: 0.07547169811320754 and parameters: {'n_estimators': 936, 'max_depth': 42, 'criterion': 'gini'}. Best is trial 0 with value: 0.15228426395939085.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 16:00:04,273]\u001b[0m Trial 3 finished with value: 0.028368794326241134 and parameters: {'n_estimators': 871, 'max_depth': 34, 'criterion': 'entropy'}. Best is trial 0 with value: 0.15228426395939085.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 16:00:05,264]\u001b[0m Trial 4 finished with value: 0.15609756097560976 and parameters: {'n_estimators': 170, 'max_depth': 71, 'criterion': 'gini'}. Best is trial 4 with value: 0.15609756097560976.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 16:00:05,776]\u001b[0m Trial 5 finished with value: 0.0 and parameters: {'n_estimators': 297, 'max_depth': 7, 'criterion': 'entropy'}. Best is trial 4 with value: 0.15609756097560976.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 16:00:08,107]\u001b[0m Trial 6 finished with value: 0.0 and parameters: {'n_estimators': 856, 'max_depth': 20, 'criterion': 'gini'}. Best is trial 4 with value: 0.15609756097560976.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 16:00:09,790]\u001b[0m Trial 7 finished with value: 0.015873015873015876 and parameters: {'n_estimators': 573, 'max_depth': 20, 'criterion': 'entropy'}. Best is trial 4 with value: 0.15609756097560976.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 16:00:10,065]\u001b[0m Trial 8 finished with value: 0.0 and parameters: {'n_estimators': 196, 'max_depth': 2, 'criterion': 'gini'}. Best is trial 4 with value: 0.15609756097560976.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 16:00:11,090]\u001b[0m Trial 9 finished with value: 0.0 and parameters: {'n_estimators': 708, 'max_depth': 2, 'criterion': 'entropy'}. Best is trial 4 with value: 0.15609756097560976.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 16:00:11,200]\u001b[0m Trial 10 finished with value: 0.16842105263157894 and parameters: {'n_estimators': 14, 'max_depth': 111, 'criterion': 'gini'}. Best is trial 10 with value: 0.16842105263157894.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 16:00:11,263]\u001b[0m Trial 11 finished with value: 0.175 and parameters: {'n_estimators': 8, 'max_depth': 127, 'criterion': 'gini'}. Best is trial 11 with value: 0.175.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 16:00:11,344]\u001b[0m Trial 12 finished with value: 0.13291139240506328 and parameters: {'n_estimators': 10, 'max_depth': 123, 'criterion': 'gini'}. Best is trial 11 with value: 0.175.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 16:00:11,434]\u001b[0m Trial 13 finished with value: 0.09039548022598871 and parameters: {'n_estimators': 13, 'max_depth': 62, 'criterion': 'gini'}. Best is trial 11 with value: 0.175.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 16:00:11,711]\u001b[0m Trial 14 finished with value: 0.0 and parameters: {'n_estimators': 162, 'max_depth': 6, 'criterion': 'gini'}. Best is trial 11 with value: 0.175.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 16:00:13,908]\u001b[0m Trial 15 finished with value: 0.1352657004830918 and parameters: {'n_estimators': 388, 'max_depth': 67, 'criterion': 'gini'}. Best is trial 11 with value: 0.175.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 16:00:14,697]\u001b[0m Trial 16 finished with value: 0.13023255813953485 and parameters: {'n_estimators': 116, 'max_depth': 127, 'criterion': 'gini'}. Best is trial 11 with value: 0.175.\u001b[0m\n",
      "\u001b[32m[I 2022-03-31 16:00:16,131]\u001b[0m Trial 17 finished with value: 0.08695652173913043 and parameters: {'n_estimators': 309, 'max_depth': 40, 'criterion': 'gini'}. Best is trial 11 with value: 0.175.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pipeline_rf(X_train_vec_b[1], y_train_b, X_valid_vec_b[1], y_valid_b, X_test_vec_b[1], y_test_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes (CNN, LSTM e BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_cnn_lstm(tuner_name,X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
    "\n",
    "    type_nn = tuner_name[:3]\n",
    "   \n",
    "    #Encoding sentences\n",
    "    encoder = networks.sentence_encoder(X_train)\n",
    "\n",
    "    #Finding best parameters\n",
    "    tuner = networks.network_tuner(type_nn, encoder, tuner_name)\n",
    "    \n",
    "    best_hp = networks.search_network(tuner, X_train, y_train, X_valid, y_valid)\n",
    "\n",
    "    #Loading best model\n",
    "    model = networks.get_model(tuner, best_hp)\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "    history = model.fit(X_train, y_train, epochs=50, validation_data = (X_valid, y_valid), callbacks=[stop_early])\n",
    "\n",
    "    #Getting test results\n",
    "    networks.get_test_metrics(model, X_test, y_test)\n",
    "    networks.plot_acuracy_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sem stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desbalanceado\n",
    "pipeline_cnn_lstm(\"cnn\",X_train_join[0], y_train, X_valid_join[0], y_valid, X_test_join[0], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanceado\n",
    "pipeline_cnn_lstm(\"cnn_b\",X_train_join_b[0], y_train_b, X_valid_join_b[0], y_valid_b, X_test_join_b[0], y_test_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Com stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desbalanceado\n",
    "pipeline_cnn_lstm(\"cnn_st\",X_train_join[1], y_train, X_valid_join[1], y_valid, X_test_join[1], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balanceado\n",
    "pipeline_cnn_lstm(\"cnn_b_st\",X_train_join_b[1], y_train_b, X_valid_join_b[1], y_valid_b, X_test_join_b[1], y_test_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sem stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desbalanceado\n",
    "pipeline_cnn_lstm(\"lstm\",X_train_join[0], y_train, X_valid_join[0], y_valid, X_test_join[0], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanceado\n",
    "pipeline_cnn_lstm(\"lstm_b\",X_train_join_b[0], y_train_b, X_valid_join_b[0], y_valid_b, X_test_join_b[0], y_test_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Com stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desbalanceado\n",
    "pipeline_cnn_lstm(\"lstm_st\",X_train_join[1], y_train, X_valid_join[1], y_valid, X_test_join[1], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balanceado\n",
    "pipeline_cnn_lstm(\"lstm_b_st\",X_train_join_b[1], y_train_b, X_valid_join_b[1], y_valid_b, X_test_join_b[1], y_test_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "\n",
    "def pipeline_bert(X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
    "\n",
    "    learning_rate = 2e-5\n",
    "    number_of_epochs = 1\n",
    "    ds_train, ds_valid, ds_test = bert.get_bert_data(X_train, y_train, X_valid, y_valid, X_test, y_test)\n",
    "    \n",
    "    # model initialization\n",
    "    model = TFBertForSequenceClassification.from_pretrained('bert-base-portuguese-cased', from_pt = True)\n",
    "\n",
    "    # choosing Adam optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "    #Training model\n",
    "    bert_history = model.fit(ds_train, epochs=number_of_epochs, validation_data=ds_valid)\n",
    "\n",
    "    #Predict test data\n",
    "    bert.get_test_metrics(model, ds_test, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sem stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unbalanced data\n",
    "pipeline_bert(X_train_join[0], y_train, X_valid_join[0], y_valid, X_test_join[0], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balanced data\n",
    "pipeline_bert(X_train_join_b[0], y_train_b, X_valid_join_b[0], y_valid_b, X_test_join_b[0]y_test_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Com stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unbalanced data\n",
    "pipeline_bert(X_train_join[1], y_train, X_valid_join[1], y_valid, X_test_join[1], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balanced data\n",
    "pipeline_bert(X_train_join_b[1], y_train_b, X_valid_join_b[1], y_valid_b, X_test_join_b[1], y_test_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp[[\"reviews\", \"reviews_pipeline_0\", \"class\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = df_pp[[\"reviews\", \"reviews_pipeline_0\", \"class\"]]\n",
    "\n",
    "X_join = df_cluster[\"reviews_pipeline_0\"].apply(\" \".join)\n",
    "X_join = X_join.to_numpy()\n",
    "#df_cluster[\"reviews_join\"] = X_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",   \n",
    "                             tokenizer = None,    \n",
    "                             preprocessor = None, \n",
    "                             stop_words = None,   \n",
    "                             max_features = 2000) \n",
    "\n",
    "#List with BoWs (pipeline 0 and 1)\n",
    "bow_vec = vectorizer.fit_transform(X_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = vectorizer.get_feature_names()\n",
    "#words = vectorizer.get_feature_names_out()\n",
    "\n",
    "#setup kmeans clustering\n",
    "kmeans = KMeans(n_clusters = 2, random_state = 420)\n",
    "#fit the data \n",
    "kmeans.fit(bow_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achar os n mais proximos (https://stackoverflow.com/questions/26795535/output-50-samples-closest-to-each-cluster-center-using-scikit-learn-k-means-libr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- n Reviews mais próximas do centróide da classe 0 (Ruim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=2\n",
    "d = kmeans.transform(csr_matrix.toarray(bow_vec))[:, 0] #distancia de cada ponto ao centroide 0\n",
    "ind0 = np.argsort(d)[::][:n]\n",
    "ind0\n",
    "#csr_matrix.toarray(bow_vec)[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp.iloc[ind0[0]][\"reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp.iloc[ind0[1]][\"reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_neg = []\n",
    "for i in ind0.tolist():\n",
    "    lista_neg.append(df_pp.iloc[i][\"reviews\"])\n",
    "lista_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- n Reviews mais próximas do centróide da classe 1 (Bom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "d = kmeans.transform(csr_matrix.toarray(bow_vec))[:, 1] #distancia de cada ponto ao centroide 1\n",
    "ind1 = np.argsort(d)[::][:n]\n",
    "ind1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp.iloc[ind1[0]][\"reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp.iloc[ind1[1]][\"reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_posi = []\n",
    "for i in ind1.tolist():\n",
    "    lista_posi.append(df_pp.iloc[i][\"reviews\"])\n",
    "lista_posi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando em um df para incluir no dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep = pd.DataFrame(data={\"negativo\": lista_neg, \"positivo\": lista_posi})\n",
    "df_rep.to_csv(\"reviews_rep.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para salvar predições do melhor classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test[\"pred\"] = result\n",
    "#df_pred = pd.merge(X_test[[\"class\", \"pred\"]], df_pp[[\"reviews\", \"stars\", \"dates\"]], left_index=True, right_index=True)\n",
    "#df_pred.to_csv(\"best_pred.csv\", index=False)\n",
    "\n",
    "def save_results(result, X_test, df_pp, dfname=\"best_pred.csv\"):\n",
    "    X_test[\"pred\"] = result\n",
    "    df_pred = pd.merge(X_test[[\"class\", \"pred\"]], df_pp[[\"reviews\", \"stars\", \"dates\"]], left_index=True, right_index=True)\n",
    "    df_pred.to_csv(dfname, index=False)\n",
    "\n",
    "save_results(result, X_test, df_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"best_pred.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8003219c8c57211ee3be347d121ba14ebad7276cdae3d94be72d9e4e17f9edd5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
