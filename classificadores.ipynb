{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto - Mineração de Texto e Web\n",
    "## Residência Engenharia e Ciência de dados - Samsung/UFPE\n",
    "\n",
    "### Lucas Couri - lncc2\n",
    "### Mariama Oliveira - mcso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.cluster.vq import vq\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from keras.datasets import mnist\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Conv2D, Input\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.plot(history.history['val_'+metric], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"reviews_v2.csv\")\n",
    "df = df[df[\"reviews\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviews    object\n",
       "stars       int64\n",
       "dates      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>stars</th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estou aqui para relatar uma experiência que ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-06-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Já havia comprado a versão Lite, o que já ac...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bom. Bem fluído, interessante e eficaz em cu...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Estou bem chateado, ja possuía o modelo anti...</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aparelho muito bom, está lidando muito bem c...</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-05-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  stars       dates\n",
       "0    Estou aqui para relatar uma experiência que ...      5  2021-06-05\n",
       "1    Já havia comprado a versão Lite, o que já ac...      5  2021-05-07\n",
       "2    Bom. Bem fluído, interessante e eficaz em cu...      5  2021-05-07\n",
       "3    Estou bem chateado, ja possuía o modelo anti...      3  2021-05-09\n",
       "4    Aparelho muito bom, está lidando muito bem c...      4  2021-05-06"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento (com e sem stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global variables\n",
    "other_punctuation = '—“”'  \n",
    "stop_words = stopwords.words('portuguese')\n",
    "stop_words.append('’')\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "\n",
    "\n",
    "#Function that removes punctuation \n",
    "def remove_punctuation(text):\n",
    "    punctuation_free_doc = \"\".join([i for i in text if i not in string.punctuation+other_punctuation])\n",
    "    return punctuation_free_doc\n",
    "\n",
    "\n",
    "def remove_stopwords(list_words):\n",
    "    filtered_words = [word for word in list_words if word not in stop_words]\n",
    "    return filtered_words\n",
    "\n",
    "\n",
    "def do_stemming(list_words):\n",
    "    stem_text = [stemmer.stem(word) for word in list_words]\n",
    "    return stem_text\n",
    "\n",
    "\n",
    "def pre_process(doc, basic_processing = False, no_stopwords = False, stemming = False):\n",
    "\n",
    "    final_doc = doc\n",
    "    \n",
    "    ## print(final_doc)\n",
    "\n",
    "    if basic_processing == True:\n",
    "        \n",
    "        final_doc = remove_punctuation(doc)\n",
    "        final_doc = final_doc.lower()\n",
    "\n",
    "    final_doc = nltk.word_tokenize(final_doc)\n",
    "\n",
    "    if no_stopwords == True:\n",
    "        final_doc = remove_stopwords(final_doc)    \n",
    "\n",
    "    if stemming == True:\n",
    "        final_doc = do_stemming(final_doc)\n",
    "\n",
    "    return final_doc\n",
    "\n",
    "def pre_process_all(df, pre_processing_list):\n",
    "\n",
    "    for param, index in zip(pre_processing_list, range(len(pre_processing_list))):\n",
    "        \n",
    "        df[f\"reviews_pipeline_{index}\"] = df[\"reviews\"].apply(lambda x: pre_process(x, **param))\n",
    "\n",
    "    return df\n",
    "\n",
    "pre_processing_list = [\n",
    "    {\"basic_processing\": True, \"no_stopwords\": True, \"stemming\": False},\n",
    "    {\"basic_processing\": True, \"no_stopwords\": True, \"stemming\": True}]\n",
    "\n",
    "df_pp = pre_process_all(df, pre_processing_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>stars</th>\n",
       "      <th>dates</th>\n",
       "      <th>reviews_pipeline_0</th>\n",
       "      <th>reviews_pipeline_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estou aqui para relatar uma experiência que ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-06-05</td>\n",
       "      <td>[aqui, relatar, experiência, visando, contribu...</td>\n",
       "      <td>[aqu, relat, experi, vis, contribu, amig, prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Já havia comprado a versão Lite, o que já ac...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-05-07</td>\n",
       "      <td>[havia, comprado, versão, lite, achei, maravil...</td>\n",
       "      <td>[hav, compr, vers, lit, ach, maravilh, porém, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bom. Bem fluído, interessante e eficaz em cu...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-05-07</td>\n",
       "      <td>[bom, bem, fluído, interessante, eficaz, cumpr...</td>\n",
       "      <td>[bom, bem, flu, interess, eficaz, cumpr, prome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Estou bem chateado, ja possuía o modelo anti...</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-05-09</td>\n",
       "      <td>[bem, chateado, ja, possuía, modelo, antigo, b...</td>\n",
       "      <td>[bem, chate, ja, possuí, model, antig, bem, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aparelho muito bom, está lidando muito bem c...</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>[aparelho, bom, lidando, bem, home, tv, apenas...</td>\n",
       "      <td>[aparelh, bom, lid, bem, hom, tv, apen, porém,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  stars       dates  \\\n",
       "0    Estou aqui para relatar uma experiência que ...      5  2021-06-05   \n",
       "1    Já havia comprado a versão Lite, o que já ac...      5  2021-05-07   \n",
       "2    Bom. Bem fluído, interessante e eficaz em cu...      5  2021-05-07   \n",
       "3    Estou bem chateado, ja possuía o modelo anti...      3  2021-05-09   \n",
       "4    Aparelho muito bom, está lidando muito bem c...      4  2021-05-06   \n",
       "\n",
       "                                  reviews_pipeline_0  \\\n",
       "0  [aqui, relatar, experiência, visando, contribu...   \n",
       "1  [havia, comprado, versão, lite, achei, maravil...   \n",
       "2  [bom, bem, fluído, interessante, eficaz, cumpr...   \n",
       "3  [bem, chateado, ja, possuía, modelo, antigo, b...   \n",
       "4  [aparelho, bom, lidando, bem, home, tv, apenas...   \n",
       "\n",
       "                                  reviews_pipeline_1  \n",
       "0  [aqu, relat, experi, vis, contribu, amig, prob...  \n",
       "1  [hav, compr, vers, lit, ach, maravilh, porém, ...  \n",
       "2  [bom, bem, flu, interess, eficaz, cumpr, prome...  \n",
       "3  [bem, chate, ja, possuí, model, antig, bem, co...  \n",
       "4  [aparelh, bom, lid, bem, hom, tv, apen, porém,...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews_pipeline_0</th>\n",
       "      <th>reviews_pipeline_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[aqui, relatar, experiência, visando, contribu...</td>\n",
       "      <td>[aqu, relat, experi, vis, contribu, amig, prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[havia, comprado, versão, lite, achei, maravil...</td>\n",
       "      <td>[hav, compr, vers, lit, ach, maravilh, porém, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bom, bem, fluído, interessante, eficaz, cumpr...</td>\n",
       "      <td>[bom, bem, flu, interess, eficaz, cumpr, prome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[bem, chateado, ja, possuía, modelo, antigo, b...</td>\n",
       "      <td>[bem, chate, ja, possuí, model, antig, bem, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[aparelho, bom, lidando, bem, home, tv, apenas...</td>\n",
       "      <td>[aparelh, bom, lid, bem, hom, tv, apen, porém,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>[chegou, super, rápido, atendeu, superou, toda...</td>\n",
       "      <td>[cheg, sup, rápid, atend, super, tod, expect]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>[facil, instalação, configuração, entrega, sup...</td>\n",
       "      <td>[facil, instal, configur, entreg, sup, rápid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>[amei, produto, unico, problema, pra, mim, nao...</td>\n",
       "      <td>[ame, produt, unic, problem, pra, mim, nao, hbo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>[funciona, beleza, rede, internet, sendo, boa,...</td>\n",
       "      <td>[func, bel, red, internet, send, boa, tud, bem]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>[aparelho, bom, penanao, poder, instalar, hbo,...</td>\n",
       "      <td>[aparelh, bom, penana, pod, instal, hbo, max]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5003 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     reviews_pipeline_0  \\\n",
       "0     [aqui, relatar, experiência, visando, contribu...   \n",
       "1     [havia, comprado, versão, lite, achei, maravil...   \n",
       "2     [bom, bem, fluído, interessante, eficaz, cumpr...   \n",
       "3     [bem, chateado, ja, possuía, modelo, antigo, b...   \n",
       "4     [aparelho, bom, lidando, bem, home, tv, apenas...   \n",
       "...                                                 ...   \n",
       "5002  [chegou, super, rápido, atendeu, superou, toda...   \n",
       "5003  [facil, instalação, configuração, entrega, sup...   \n",
       "5004  [amei, produto, unico, problema, pra, mim, nao...   \n",
       "5005  [funciona, beleza, rede, internet, sendo, boa,...   \n",
       "5006  [aparelho, bom, penanao, poder, instalar, hbo,...   \n",
       "\n",
       "                                     reviews_pipeline_1  \n",
       "0     [aqu, relat, experi, vis, contribu, amig, prob...  \n",
       "1     [hav, compr, vers, lit, ach, maravilh, porém, ...  \n",
       "2     [bom, bem, flu, interess, eficaz, cumpr, prome...  \n",
       "3     [bem, chate, ja, possuí, model, antig, bem, co...  \n",
       "4     [aparelh, bom, lid, bem, hom, tv, apen, porém,...  \n",
       "...                                                 ...  \n",
       "5002      [cheg, sup, rápid, atend, super, tod, expect]  \n",
       "5003      [facil, instal, configur, entreg, sup, rápid]  \n",
       "5004   [ame, produt, unic, problem, pra, mim, nao, hbo]  \n",
       "5005    [func, bel, red, internet, send, boa, tud, bem]  \n",
       "5006      [aparelh, bom, penana, pod, instal, hbo, max]  \n",
       "\n",
       "[5003 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pp[[\"reviews_pipeline_0\", \"reviews_pipeline_1\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp[\"class\"] = df_pp[\"stars\"].apply(lambda x : 1 if x >=4 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that oversaples given a dataframe\n",
    "def perform_oversample(df):\n",
    "\n",
    "    class_1,class_0 = df[\"class\"].value_counts()\n",
    "    c0 = df[df['class'] == 0]\n",
    "    c1 = df[df['class'] == 1]\n",
    "\n",
    "    df_0 = c0.sample(round(class_1/3), replace=True)\n",
    "    oversampled_df = pd.concat([c1,df_0], axis=0)\n",
    "\n",
    "    return oversampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão train e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define if it will perform oversampling\n",
    "OVERSAMPLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pp[[\"reviews_pipeline_0\", \"reviews_pipeline_1\", \"class\"]]\n",
    "y = df_pp[\"class\"]\n",
    "X_train_valid, X_test, y_train_valid, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size = 0.3, random_state = 42, stratify=y_train_valid)\n",
    "\n",
    "if OVERSAMPLE:\n",
    "    X_train = perform_oversample(X_train)\n",
    "    \n",
    "y_train =  X_train[\"class\"]    \n",
    "X_train = X_train[[\"reviews_pipeline_0\", \"reviews_pipeline_1\"]]\n",
    "\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformando tokens em string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_join = []\n",
    "X_train_join.append(X_train[\"reviews_pipeline_0\"].apply(\" \".join))\n",
    "X_train_join.append(X_train[\"reviews_pipeline_1\"].apply(\" \".join))\n",
    "X_train_join[0] = X_train_join[0].to_numpy()\n",
    "X_train_join[1] = X_train_join[1].to_numpy()\n",
    "\n",
    "X_test_join = []\n",
    "X_test_join.append(X_test[\"reviews_pipeline_0\"].apply(\" \".join))\n",
    "X_test_join.append(X_test[\"reviews_pipeline_1\"].apply(\" \".join))\n",
    "X_test_join[0] = X_test_join[0].to_numpy()\n",
    "X_test_join[1] = X_test_join[1].to_numpy()\n",
    "\n",
    "X_valid_join = []\n",
    "X_valid_join.append(X_valid[\"reviews_pipeline_0\"].apply(\" \".join))\n",
    "X_valid_join.append(X_valid[\"reviews_pipeline_1\"].apply(\" \".join))\n",
    "X_valid_join[0] = X_valid_join[0].to_numpy()\n",
    "X_valid_join[1] = X_valid_join[1].to_numpy()\n",
    "\n",
    "X_train_valid_join = []\n",
    "X_train_valid_join.append(X_train_valid[\"reviews_pipeline_0\"].apply(\" \".join))\n",
    "X_train_valid_join.append(X_train_valid[\"reviews_pipeline_1\"].apply(\" \".join))\n",
    "X_train_valid_join[0] = X_train_valid_join[0].to_numpy()\n",
    "X_train_valid_join[1] = X_train_valid_join[1].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificadores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest com BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",   \n",
    "                             tokenizer = None,    \n",
    "                             preprocessor = None, \n",
    "                             stop_words = None,   \n",
    "                             max_features = 2000) \n",
    "\n",
    "#List with BoWs (pipeline 0 and 1)\n",
    "X_train_vec = []\n",
    "X_train_vec.append(vectorizer.fit_transform(X_train_valid_join[0]))\n",
    "X_train_vec.append(vectorizer.fit_transform(X_train_valid_join[1]))\n",
    "\n",
    "X_test_vec = []\n",
    "X_test_vec.append(vectorizer.fit_transform(X_test_join[0]))\n",
    "X_test_vec.append(vectorizer.fit_transform(X_test_join[1]))\n",
    "\n",
    "# X_valid_vec = []\n",
    "# X_valid_vec.append(vectorizer.fit_transform(X_valid_join[0]))\n",
    "# X_valid_vec.append(vectorizer.fit_transform(X_valid_join[1]))\n",
    "\n",
    "\n",
    "print(X_train_vec[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "cv = model_selection.StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "def objective(trial):\n",
    "      iris = sklearn.datasets.load_iris()\n",
    "      n_estimators = trial.suggest_int('n_estimators', 2, 20)\n",
    "      max_depth = int(trial.suggest_loguniform('max_depth', 1, 32))\n",
    "      clf = sklearn.ensemble.RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "      return sklearn.model_selection.cross_val_score(clf, iris.data, iris.target, \n",
    "           n_jobs=-1, cv=3).mean()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_rf(X_train, y_train, parameters, cv, SEED):\n",
    "\n",
    "    rf = RandomForestClassifier(random_state = SEED)\n",
    "\n",
    "    search = GridSearchCV(rf,\n",
    "                          parameters,\n",
    "                          scoring = \"accuracy\",\n",
    "                          n_jobs = -1,\n",
    "                          cv = cv)\n",
    "\n",
    "    result_rf = search.fit(X_train, y_train)\n",
    "    \n",
    "    print('=========Resultados do Grid Search para Random Forest==========')\n",
    "    print(f'Melhor Score: {result_rf.best_score_}')\n",
    "    print(f'Melhores Hiperparâmetros: {result_rf.best_params_}')\n",
    "\n",
    "    return result_rf\n",
    "\n",
    "parameters = dict()\n",
    "parameters['n_estimators'] = range(10, 101, 10)\n",
    "parameters['criterion'] = [\"gini\", \"entropy\"]\n",
    "#parameters['max_features'] = [\"auto\", \"sqrt\", \"log2\"]\n",
    "#parameters['min_samples_leaf'] = [1, 4]\n",
    "#parameters['min_samples_split'] = [2, 10]\n",
    "#parameters['max_depth'] = [10, 100, None]#[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None]\n",
    "\n",
    "result_rf_0 = val_rf(X_train_vec[0], y_train_valid, parameters, cv, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(**result_rf_0.best_params_) \n",
    "forest = forest.fit(X_train_vec[0], y_train_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = forest.predict(X_test_vec[0]) \n",
    "result = forest.predict(X_test_vec[0])\n",
    "print(classification_report(y_test, result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Com Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict()\n",
    "parameters['n_estimators'] = range(10, 101, 10)\n",
    "parameters['criterion'] = [\"gini\", \"entropy\"]\n",
    "#parameters['max_features'] = [\"auto\", \"sqrt\", \"log2\"]\n",
    "#parameters['min_samples_leaf'] = [1, 4]\n",
    "#parameters['min_samples_split'] = [2, 10]\n",
    "#parameters['max_depth'] = [10, 100, None]#[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None]\n",
    "\n",
    "result_rf_1 = val_rf(X_train_vec[1], y_train_valid, parameters, cv, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(**result_rf_1.best_params_) \n",
    "forest = forest.fit(X_train_vec[1], y_train_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = forest.predict(X_test_vec[1]) \n",
    "result = forest.predict(X_test_vec[1])\n",
    "print(classification_report(y_test, result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes (CNN, LSTM e BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.layers.TextVectorization(\n",
    "#     max_tokens=None,\n",
    "#     standardize='lower_and_strip_punctuation',\n",
    "#     split='whitespace',\n",
    "#     ngrams=None,\n",
    "#     output_mode='int',\n",
    "#     output_sequence_length=None,\n",
    "#     pad_to_max_tokens=False,\n",
    "#     vocabulary=None,\n",
    "#     idf_weights=None,\n",
    "#     sparse=False,\n",
    "#     ragged=False,\n",
    "#     **kwargs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_join[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder (Sem stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "encoder_0 = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE,\n",
    "                                            standardize=None\n",
    "                                            )\n",
    "#encoder.adapt(train_dataset.map(lambda text, label: text))\n",
    "encoder_0.adapt(X_train_join[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[566   2 525 ...   0   0   0]\n",
      " [  3  15   6 ...   0   0   0]\n",
      " [  3  70 310 ...   0   0   0]\n",
      " ...\n",
      " [  9  37  31 ...   0   0   0]\n",
      " [  1 130  28 ...   0   0   0]\n",
      " [ 13   9   5 ...   0   0   0]], shape=(2905, 180), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "vectorized_text = encoder_0(X_train_join[0])\n",
    "print(vectorized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'tv', 'produto', 'controle', 'fácil', 'bem', 'alexa',\n",
       "       'fire', 'bom', 'instalar', 'stick', 'hbo', 'aparelho', 'amazon',\n",
       "       'funciona', 'ter', 'tudo', 'max', 'smart'], dtype='<U17')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(encoder_0.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder (Com stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "encoder_1 = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE,\n",
    "                                            standardize=None\n",
    "                                            )\n",
    "#encoder.adapt(train_dataset.map(lambda text, label: text))\n",
    "encoder_1.adapt(X_train_join[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 99   2 361 ...   0   0   0]\n",
      " [  4  20   7 ...   0   0   0]\n",
      " [  4  25 300 ...   0   0   0]\n",
      " ...\n",
      " [ 11  14  12 ...   0   0   0]\n",
      " [252   3  39 ...   0   0   0]\n",
      " [ 16  11   6 ...   0   0   0]], shape=(2905, 180), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "vectorized_text = encoder_1(X_train_join[1])\n",
    "print(vectorized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'tv', 'control', 'produt', 'instal', 'fácil', 'bem',\n",
       "       'compr', 'alex', 'fir', 'bom', 'app', 'funcion', 'tod', 'stick',\n",
       "       'aparelh', 'aplic', 'hbo', 'amazon'], dtype='<U16')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(encoder_1.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sem stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "##Testando keras tuner\n",
    "\n",
    "def model_builder_0(hp):\n",
    "\n",
    "    # hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    hp_rate = hp.Float('dropout_1', min_value=0.0, max_value=0.5, default=0.25, step=0.05)\n",
    "\n",
    "    model_CNN_0 = tf.keras.Sequential([\n",
    "    encoder_0,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder_0.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=8, activation='relu'),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2),\n",
    "    #tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(rate=hp_rate),\n",
    "    # tf.keras.layers.Dense(units=hp_units, activation='relu'), #>>>>>Hiperparametro\n",
    "    tf.keras.layers.GlobalMaxPool1D(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model_CNN_0.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate), #>>>>>Hiperparametro\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    return model_CNN_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_CNN_0 = tf.keras.Sequential([\n",
    "#     encoder_0,\n",
    "#     tf.keras.layers.Embedding(\n",
    "#         input_dim=len(encoder_0.get_vocabulary()),\n",
    "#         output_dim=64,\n",
    "#         # Use masking to handle the variable sequence lengths\n",
    "#         mask_zero=True),\n",
    "#     tf.keras.layers.Conv1D(filters=32, kernel_size=8, activation='relu'),\n",
    "#     tf.keras.layers.MaxPool1D(pool_size=2),\n",
    "#     #tf.keras.layers.Flatten(),    \n",
    "#     tf.keras.layers.Dense(32, activation='relu'),\n",
    "#     tf.keras.layers.GlobalMaxPool1D(),\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model_CNN_0.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_CNN_0.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "#               optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model_CNN_0.fit(X_train_join[0], y_train, epochs=30,\n",
    "#                     batch_size = 32,\n",
    "#                     validation_data= (X_valid_join[0], y_valid),\n",
    "#                     validation_steps=30\n",
    "#                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the tuner\n",
    "tuner = kt.Hyperband(model_builder_0, # the hypermodel\n",
    "                     objective='val_accuracy', # objective to optimize\n",
    "max_epochs=50,\n",
    "factor=3, # factor which you have seen above \n",
    "directory='tuner', # directory to save logs \n",
    "project_name='cnn_0_bal_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 2\n",
      "dropout_1 (Float)\n",
      "{'default': 0.25, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.05, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "# hypertuning settings\n",
    "tuner.search_space_summary() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 01s]\n",
      "val_accuracy: 0.8886774778366089\n",
      "\n",
      "Best val_accuracy So Far: 0.8896289467811584\n",
      "Total elapsed time: 00h 01m 01s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "# Perform hypertuning\n",
    "tuner.search(X_train_join[1], y_train, epochs=50, validation_data = (X_valid_join[0], y_valid), callbacks=[stop_early])\n",
    "best_hp = tuner.get_best_hyperparameters()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, None)             0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, None, 64)          64000     \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, None, 32)          16416     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, None, 32)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, None, 32)          0         \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 32)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,449\n",
      "Trainable params: 80,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters\n",
    "model_CNN_0 = tuner.hypermodel.build(best_hp)\n",
    "model_CNN_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "91/91 [==============================] - 1s 10ms/step - loss: 0.5412 - accuracy: 0.7518 - val_loss: 0.4528 - val_accuracy: 0.8896\n",
      "Epoch 2/50\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 0.3576 - accuracy: 0.8420 - val_loss: 0.3231 - val_accuracy: 0.8982\n",
      "Epoch 3/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 0.1808 - accuracy: 0.9408 - val_loss: 0.2513 - val_accuracy: 0.9020\n",
      "Epoch 4/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 0.1121 - accuracy: 0.9611 - val_loss: 0.2418 - val_accuracy: 0.9068\n",
      "Epoch 5/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 0.0691 - accuracy: 0.9824 - val_loss: 0.2460 - val_accuracy: 0.9039\n",
      "Epoch 6/50\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 0.0462 - accuracy: 0.9910 - val_loss: 0.2551 - val_accuracy: 0.9058\n",
      "Epoch 7/50\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 0.0303 - accuracy: 0.9948 - val_loss: 0.2725 - val_accuracy: 0.9039\n",
      "Epoch 8/50\n",
      "91/91 [==============================] - 1s 8ms/step - loss: 0.0202 - accuracy: 0.9969 - val_loss: 0.2869 - val_accuracy: 0.9077\n",
      "Epoch 9/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 0.0138 - accuracy: 0.9972 - val_loss: 0.3059 - val_accuracy: 0.9001\n"
     ]
    }
   ],
   "source": [
    "history = model_CNN_0.fit(X_train_join[0], y_train, epochs=50, validation_data = (X_valid_join[0], y_valid), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3559 - accuracy: 0.8867\n",
      "Test Loss: 0.3558889925479889\n",
      "Test Accuracy: 0.8867421746253967\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_CNN_0.evaluate(X_test_join[0], y_test)\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.37      0.42       167\n",
      "           1       0.92      0.95      0.94      1334\n",
      "\n",
      "    accuracy                           0.89      1501\n",
      "   macro avg       0.71      0.66      0.68      1501\n",
      "weighted avg       0.88      0.89      0.88      1501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = model_CNN_0.predict(X_test_join[0])\n",
    "result = np.where(result > 0.5, 1, 0)\n",
    "result\n",
    "\n",
    "print(classification_report(y_test, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  62,  105],\n",
       "       [  65, 1269]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.5676024262793362)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.ylim(None, 1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_graphs(history, 'loss')\n",
    "plt.ylim(0, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Com stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_CNN_1 = tf.keras.Sequential([\n",
    "#     encoder_1,\n",
    "#     tf.keras.layers.Embedding(\n",
    "#         input_dim=len(encoder_1.get_vocabulary()),\n",
    "#         output_dim=64,\n",
    "#         # Use masking to handle the variable sequence lengths\n",
    "#         mask_zero=True),\n",
    "#     tf.keras.layers.Conv1D(filters=32, kernel_size=8, activation='relu'),\n",
    "#     tf.keras.layers.MaxPool1D(pool_size=2),\n",
    "#     #tf.keras.layers.Flatten(),    \n",
    "#     tf.keras.layers.Dense(32, activation='relu'),\n",
    "#     tf.keras.layers.GlobalMaxPool1D(),\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "##Testando keras tuner\n",
    "\n",
    "def model_builder_1(hp):\n",
    "\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "\n",
    "    model_CNN_1 = tf.keras.Sequential([\n",
    "    encoder_1,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder_1.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=8, activation='relu'),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2),\n",
    "    #tf.keras.layers.Flatten(),    \n",
    "    tf.keras.layers.Dense(units=hp_units, activation='relu'), #>>>>>Hiperparametro\n",
    "    tf.keras.layers.GlobalMaxPool1D(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model_CNN_1.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate), #>>>>>Hiperparametro\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    return model_CNN_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the tuner\n",
    "tuner = kt.Hyperband(model_builder_1, # the hypermodel\n",
    "                     objective='val_accuracy', # objective to optimize\n",
    "max_epochs=10,\n",
    "factor=3, # factor which you have seen above \n",
    "directory='tuner', # directory to save logs \n",
    "project_name='cnn_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypertuning settings\n",
    "tuner.search_space_summary() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "# Perform hypertuning\n",
    "tuner.search(X_train_join[1], y_train, epochs=10, validation_data = (X_valid_join[1], y_valid), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hp = tuner.get_best_hyperparameters()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with the optimal hyperparameters\n",
    "model_CNN_1 = tuner.hypermodel.build(best_hp)\n",
    "model_CNN_1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_CNN_1.fit(X_train_join[1], y_train, epochs=10, validation_data = (X_valid_join[1], y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model_CNN_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_CNN_1.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "#               optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model_CNN_1.fit(X_train_join[1], y_train, epochs=20,\n",
    "#                     batch_size = 32,\n",
    "#                     validation_data= (X_valid_join[1], y_valid),\n",
    "#                     validation_steps=3\n",
    "#                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_loss, test_acc = model_CNN_1.evaluate(X_test_join[1], y_test)\n",
    "test_loss, test_acc = model_CNN_1.evaluate(X_test_join[1], y_test)\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = h_model.predict(X_test_join[1])\n",
    "result = np.where(result > 0.5, 1, 0)\n",
    "result\n",
    "\n",
    "print(classification_report(y_test, result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.ylim(None, 1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_graphs(history, 'loss')\n",
    "plt.ylim(0, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LSTM0 = tf.keras.Sequential([\n",
    "    encoder_0,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder_0.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LSTM0.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_LSTM0.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sem stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_LSTM0.fit(X_train_join[0], y_train, epochs=20,\n",
    "                    batch_size = 32,\n",
    "                    validation_data= (X_valid_join[0], y_valid),\n",
    "                    validation_steps=30\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model_LSTM0.evaluate(X_test_join[0], y_test)\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_LSTM0.predict(X_test_join[0])\n",
    "result = np.where(result > 0.5, 1, 0)\n",
    "result\n",
    "\n",
    "print(classification_report(y_test, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.ylim(None, 1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_graphs(history, 'loss')\n",
    "plt.ylim(0, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Com stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LSTM1 = tf.keras.Sequential([\n",
    "    encoder_1,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder_1.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LSTM1.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_LSTM1.fit(X_train_join[1], y_train, epochs=10,\n",
    "                    batch_size = 32,\n",
    "                    validation_data= (X_valid_join[1], y_valid),\n",
    "                    validation_steps=30\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model_LSTM1.evaluate(X_test_join[1], y_test)\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_LSTM1.predict(X_test_join[1])\n",
    "result = np.where(result > 0.5, 1, 0)\n",
    "result\n",
    "\n",
    "print(classification_report(y_test, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.ylim(None, 1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_graphs(history, 'loss')\n",
    "plt.ylim(0, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_example_to_feature(review):\n",
    "  return tokenizer.encode_plus(review,\n",
    "                add_special_tokens = True, # add [CLS], [SEP]\n",
    "                max_length = max_length, # max length of the text that can go to BERT\n",
    "                pad_to_max_length = True, # add [PAD] tokens\n",
    "                return_attention_mask = True, # add attention mask to not focus on pad tokens\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be up to 512 for BERT\n",
    "max_length = 256\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_example_to_dict(input_ids, attention_masks, token_type_ids, label):\n",
    "  return {\n",
    "      \"input_ids\": input_ids,\n",
    "      \"token_type_ids\": token_type_ids,\n",
    "      \"attention_mask\": attention_masks,\n",
    "  }, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_examples(texts, labels, limit=-1):\n",
    "  # prepare list, so that we can build up final TensorFlow dataset from slices.\n",
    "  input_ids_list = []\n",
    "  token_type_ids_list = []\n",
    "  attention_mask_list = []\n",
    "  label_list = []\n",
    "  if (limit > 0):\n",
    "      ds = ds.take(limit)\n",
    "  # for review, label in tfds.as_numpy(ds):\n",
    "  for text, label in zip(texts, labels):\n",
    "    bert_input = convert_example_to_feature(text)\n",
    "    input_ids_list.append(bert_input['input_ids'])\n",
    "    token_type_ids_list.append(bert_input['token_type_ids'])\n",
    "    attention_mask_list.append(bert_input['attention_mask'])\n",
    "    label_list.append([label])\n",
    "  return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list, label_list)).map(map_example_to_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sem stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2226: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# train dataset\n",
    "ds_train_encoded_0 = encode_examples(X_train_join[0], y_train).shuffle(3).batch(batch_size)\n",
    "\n",
    "# test dataset\n",
    "ds_test_encoded_0 = encode_examples(X_test_join[0], y_test).batch(batch_size)\n",
    "\n",
    "#validation dataset\n",
    "ds_valid_encoded_0 = encode_examples(X_valid_join[0], y_valid).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "# recommended learning rate for Adam 5e-5, 3e-5, 2e-5\n",
    "learning_rate = 2e-5\n",
    "# we will do just 1 epoch, though multiple epochs might be better as long as we will not overfit the model\n",
    "number_of_epochs = 3\n",
    "# model initialization\n",
    "model_bert_0 = TFBertForSequenceClassification.from_pretrained('bert-base-portuguese-cased', from_pt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing Adam optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08)\n",
    "# we do not have one-hot vectors, we can use sparce categorical cross entropy and accuracy\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model_bert_0.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_history = model_bert_0.fit(ds_train_encoded_0, epochs=number_of_epochs, validation_data=ds_valid_encoded_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_output = model_bert_0.predict(ds_test_encoded_0)[0]\n",
    "tf_prediction = tf.nn.softmax(tf_output, axis=1)\n",
    "labels = ['Negative','Positive'] #(0:negative, 1:positive)\n",
    "label = tf.argmax(tf_prediction, axis=1)\n",
    "label_pred = label.numpy()\n",
    "print(label_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(label_pred, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, label_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Com stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset\n",
    "ds_train_encoded_1 = encode_examples(X_train_join[1], y_train).shuffle(3).batch(batch_size)\n",
    "\n",
    "# test dataset\n",
    "ds_test_encoded_1 = encode_examples(X_test_join[1], y_test).batch(batch_size)\n",
    "\n",
    "#validation dataset\n",
    "ds_valid_encoded_1 = encode_examples(X_valid_join[1], y_valid).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "# recommended learning rate for Adam 5e-5, 3e-5, 2e-5\n",
    "learning_rate = 2e-5\n",
    "# we will do just 1 epoch, though multiple epochs might be better as long as we will not overfit the model\n",
    "number_of_epochs = 3\n",
    "# model initialization\n",
    "model_bert_1 = TFBertForSequenceClassification.from_pretrained('bert-base-portuguese-cased', from_pt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing Adam optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08)\n",
    "# we do not have one-hot vectors, we can use sparce categorical cross entropy and accuracy\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model_bert_1.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_history = model_bert_1.fit(ds_train_encoded_1, epochs=number_of_epochs, validation_data=ds_valid_encoded_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_output = model_bert_1.predict(ds_test_encoded_1)[0]\n",
    "tf_prediction = tf.nn.softmax(tf_output, axis=1)\n",
    "labels = ['Negative','Positive'] #(0:negative, 1:positive)\n",
    "label = tf.argmax(tf_prediction, axis=1)\n",
    "label_pred = label.numpy()\n",
    "print(label_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(label_pred, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, label_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp[[\"reviews\", \"reviews_pipeline_0\", \"class\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = df_pp[[\"reviews\", \"reviews_pipeline_0\", \"class\"]]\n",
    "\n",
    "X_join = df_cluster[\"reviews_pipeline_0\"].apply(\" \".join)\n",
    "X_join = X_join.to_numpy()\n",
    "#df_cluster[\"reviews_join\"] = X_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",   \n",
    "                             tokenizer = None,    \n",
    "                             preprocessor = None, \n",
    "                             stop_words = None,   \n",
    "                             max_features = 2000) \n",
    "\n",
    "#List with BoWs (pipeline 0 and 1)\n",
    "bow_vec = vectorizer.fit_transform(X_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = vectorizer.get_feature_names()\n",
    "#words = vectorizer.get_feature_names_out()\n",
    "\n",
    "#setup kmeans clustering\n",
    "kmeans = KMeans(n_clusters = 2, random_state = 420)\n",
    "#fit the data \n",
    "kmeans.fit(bow_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/k-means-clustering-chardonnay-reviews-using-scikit-learn-nltk-9df3c59527f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Palavras mais comuns em cada cluster\n",
    "common_words = kmeans.cluster_centers_.argsort()[:,-1:-11:-1]\n",
    "for num, centroid in enumerate(common_words):\n",
    "    print(str(num) + ' : ' + ', '.join(words[word] for word in centroid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando distancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, csr_matrix.toarray(bow_vec))\n",
    "closest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando vector quantization (https://stackoverflow.com/questions/21660937/get-nearest-point-to-centroid-scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centroids: N-dimensional array with your centroids\n",
    "# points:    N-dimensional array with your data points\n",
    "closest, distances = vq(kmeans.cluster_centers_, csr_matrix.toarray(bow_vec))\n",
    "closest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/39766593/get-element-closest-to-cluster-centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def find_k_closest(centroids, data, k=1, distance_norm=2):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    ----------\n",
    "        centroids: (M, d) ndarray\n",
    "            M - number of clusters\n",
    "            d - number of data dimensions\n",
    "        data: (N, d) ndarray\n",
    "            N - number of data points\n",
    "        k: int (default 1)\n",
    "            nearest neighbour to get\n",
    "        distance_norm: int (default 2)\n",
    "            1: Hamming distance (x+y)\n",
    "            2: Euclidean distance (sqrt(x^2 + y^2))\n",
    "            np.inf: maximum distance in any dimension (max((x,y)))\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "        indices: (M,) ndarray\n",
    "        values: (M, d) ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    kdtree = cKDTree(data)\n",
    "    distances, indices = kdtree.query(centroids, k, p=distance_norm)\n",
    "    if k > 1:\n",
    "        indices = indices[:,-1]\n",
    "    values = data[indices]\n",
    "    return indices, values\n",
    "\n",
    "indices, values = find_k_closest(kmeans.cluster_centers_, csr_matrix.toarray(bow_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achar os n mais proximos (https://stackoverflow.com/questions/26795535/output-50-samples-closest-to-each-cluster-center-using-scikit-learn-k-means-libr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- n Reviews mais próximas do centróide da classe 0 (Ruim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=3\n",
    "d = kmeans.transform(csr_matrix.toarray(bow_vec))[:, 0] #distancia de cada ponto ao centroide 0\n",
    "ind0 = np.argsort(d)[::][:n]\n",
    "ind0\n",
    "#csr_matrix.toarray(bow_vec)[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp.iloc[3650]#[\"reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp.iloc[3650][\"reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp.iloc[4823]#[\"reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp.iloc[4823][\"reviews\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- n Reviews mais próximas do centróide da classe 1 (Bom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "d = kmeans.transform(csr_matrix.toarray(bow_vec))[:, 1] #distancia de cada ponto ao centroide 1\n",
    "ind1 = np.argsort(d)[::][:n]\n",
    "ind1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp.iloc[3603]#[\"reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp.iloc[3217]#[\"reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp.iloc[3998]#[\"reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test[\"pred\"] = result\n",
    "#df_pred = pd.merge(X_test[[\"class\", \"pred\"]], df_pp[[\"reviews\", \"stars\", \"dates\"]], left_index=True, right_index=True)\n",
    "#df_pred.to_csv(\"best_pred.csv\", index=False)\n",
    "\n",
    "def save_results(result, X_test, df_pp, dfname=\"best_pred.csv\"):\n",
    "    X_test[\"pred\"] = result\n",
    "    df_pred = pd.merge(X_test[[\"class\", \"pred\"]], df_pp[[\"reviews\", \"stars\", \"dates\"]], left_index=True, right_index=True)\n",
    "    df_pred.to_csv(dfname, index=False)\n",
    "\n",
    "save_results(result, X_test, df_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>pred</th>\n",
       "      <th>reviews</th>\n",
       "      <th>stars</th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Melhor compra que já fiz.Entrega super rápid...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-12-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Produto de primeira qualidade, fácil instala...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-11-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Gostei muito do produto. Tem diversos app qu...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Não sei o que aconteceu, pode ter caido o co...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>O que mais gostei foi que ligando ele a TV l...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Perfeito, o unico problema e que a minha tv ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Aparelho bem veloz e intuitivo, falta alguns...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Não funciona em qualquer televisão, me senti...</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-10-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ótimo aparelho!Fácil de manusear, instalar. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-12-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Gostei do produto, só não gostei da entrega ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-09-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1501 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class  pred                                            reviews  stars  \\\n",
       "0         1     1    Melhor compra que já fiz.Entrega super rápid...      5   \n",
       "1         1     1    Produto de primeira qualidade, fácil instala...      5   \n",
       "2         1     1    Gostei muito do produto. Tem diversos app qu...      5   \n",
       "3         1     1    Não sei o que aconteceu, pode ter caido o co...      5   \n",
       "4         1     1    O que mais gostei foi que ligando ele a TV l...      5   \n",
       "...     ...   ...                                                ...    ...   \n",
       "1496      1     1    Perfeito, o unico problema e que a minha tv ...      5   \n",
       "1497      1     1    Aparelho bem veloz e intuitivo, falta alguns...      5   \n",
       "1498      0     1    Não funciona em qualquer televisão, me senti...      2   \n",
       "1499      1     1    Ótimo aparelho!Fácil de manusear, instalar. ...      5   \n",
       "1500      1     1    Gostei do produto, só não gostei da entrega ...      5   \n",
       "\n",
       "           dates  \n",
       "0     2021-12-04  \n",
       "1     2021-11-29  \n",
       "2     2021-06-28  \n",
       "3     2021-08-27  \n",
       "4     2021-12-10  \n",
       "...          ...  \n",
       "1496  2022-01-05  \n",
       "1497  2021-06-01  \n",
       "1498  2021-10-23  \n",
       "1499  2021-12-16  \n",
       "1500  2021-09-30  \n",
       "\n",
       "[1501 rows x 5 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"best_pred.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8003219c8c57211ee3be347d121ba14ebad7276cdae3d94be72d9e4e17f9edd5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
